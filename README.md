RL-Drive-MultiAgent: Navigation with Multiple Q-Learning AgentsThis project implements a Multi-Agent Reinforcement Learning (MARL) system where several autonomous vehicles (agents) learn how to reach a target position on a 2D grid while avoiding obstacles and collisions.+1üöÄ Project OverviewIn this simulation, multiple agents share the same environment but maintain independent Q-tables to learn their own navigation strategies. The goal is to maximize cumulative rewards by reaching the target while minimizing penalties from collisions.+1üß† Learning Mechanisms & ObjectivesQ-Learning Implementation: Agents learn optimal paths by implementing and training a Q-Learning algorithm from scratch.+1Action Space: Each agent can take one of four actions per step: Up, Down, Left, or Right.Reward Structure:Goal Reach: $+100$ points for successfully reaching the randomly placed target.+1Collision: $-10$ penalty for hitting an obstacle or another agent.Movement Cost: $-1$ cost for each regular step to encourage path optimization.Exploration Strategy: Uses an Epsilon-Greedy approach starting at $\epsilon=1.0$ with a decay of $0.995$ per episode, down to a minimum of $0.05$.üõ†Ô∏è Technical Stack & ParametersLanguage: Python.+2Simulation Engine: Pygame for real-time grid, agent, and obstacle visualization.+1Analysis: Matplotlib for plotting training logs and performance metrics.+2Hyperparameters:Learning Rate ($\alpha$): $0.1$.Discount Factor ($\gamma$): $0.95$.Episodes: $300$.Grid Size: $100 \times 100$ cells.Agent Count: 50 agents (configurable).üìÇ Repository Structuresrc/: Core source files including config.py for parameters and utils.py for plotting.+2logs/: Contains training_log_multi.txt which logs Episode, Agent, TotalReward, Status, and Epsilon.+1assets/: (Recommended) Place your simulation GIFs and performance plots here.Report.pdf: A 1-page report describing chosen parameters, observed learning behavior, and possible improvements.üéÆ Simulation PreviewNote: As episodes progress, the log shows decreasing epsilon values and more "ReachedGoal" results as agents optimize their navigation.üìä Evaluation CriteriaThe project is evaluated based on:Correctness: Multi-agent Q-learning implementation.Environment Design: Proper reward logic and grid setup.Visualization: Quality and usability of the Pygame interface.Analysis: Quality of logging and performance evaluation.
